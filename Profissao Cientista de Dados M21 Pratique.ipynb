{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mEckgFd-NN6"
   },
   "source": [
    "# **M√ìDULO 21 - Projeto de Credit Score - √Årvore de Decis√£o**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0glG_vNy-UJb"
   },
   "source": [
    "No m√≥dulo 17, voc√™s realizaram a primeira etapa do projeto de cr√©dito de voc√™s. Ent√£o fizeram o tratamendo dos dados, balancearam as classes, transformaram as vari√°veis categ√≥ricas e separam base de treino e teste. J√° no m√≥dulo 14, aplicaram a base j√° tratada o algoritmo de Naive Bayes, onde avaliaram os resultados das previs√µes. Nesse m√≥dulo aplicaremos a nossa base o algoritmo da √°rvore de decis√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JJKbQFtKyfip"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos encontrados na pasta:\n",
      "CREDIT_SCORE_PROJETO_PARTE1.csv\n",
      "MODULO7.csv\n",
      "X_test.csv\n",
      "X_train_balanced.csv\n",
      "y_test.csv\n",
      "y_train_balanced.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "caminho = r'C:\\Users\\msn_j.000\\Desktop\\henry estudo ebac\\atividades feitas'\n",
    "\n",
    "# Mostrar todos os arquivos CSV na pasta\n",
    "print(\"Arquivos encontrados na pasta:\")\n",
    "for arquivo in os.listdir(caminho):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        print(arquivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piJZ3_sx-uvS"
   },
   "source": [
    "# 1) Comece carregando as bases de treino (X e y) e teste (X e y).\n",
    "Verifique se o n√∫mero de linhas condiz, se as vari√°veis est√£o corretas sendo apenas a de score para y e as demais nas bases de X e por √∫ltimo, se Y est√° balanceada no teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBjhq9xY-xoQ"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\msn_j.000\\\\Desktop\\\\henry estudo ebac\\\\atividades feitas\\\\X_treino.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m caminho \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmsn_j.000\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhenry estudo ebac\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124matividades feitas\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Carregando as bases\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_treino \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaminho\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mX_treino.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_treino \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaminho\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124my_treino.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m X_teste  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaminho\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mX_teste.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\msn_j.000\\\\Desktop\\\\henry estudo ebac\\\\atividades feitas\\\\X_treino.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho base dos arquivos\n",
    "caminho = r'C:\\Users\\msn_j.000\\Desktop\\henry estudo ebac\\atividades feitas'\n",
    "\n",
    "# Carregando as bases corretas\n",
    "X_treino = pd.read_csv(fr'{caminho}\\X_train_balanced.csv')\n",
    "y_treino = pd.read_csv(fr'{caminho}\\y_train_balanced.csv')\n",
    "X_teste  = pd.read_csv(fr'{caminho}\\X_test.csv')\n",
    "y_teste  = pd.read_csv(fr'{caminho}\\y_test.csv')\n",
    "\n",
    "# Verificando se deu tudo certo\n",
    "print(\"‚úÖ Formas das bases:\")\n",
    "print(\"X_treino:\", X_treino.shape)\n",
    "print(\"y_treino:\", y_treino.shape)\n",
    "print(\"X_teste:\", X_teste.shape)\n",
    "print(\"y_teste:\", y_teste.shape)\n",
    "\n",
    "# Conferindo colunas e distribui√ß√£o das classes\n",
    "print(\"\\nüìã Colunas de X_treino:\", X_treino.columns.tolist())\n",
    "print(\"\\nüìä Distribui√ß√£o das classes em y_treino:\")\n",
    "print(y_treino['score'].value_counts(normalize=True))\n",
    "print(\"\\nüìä Distribui√ß√£o das classes em y_teste:\")\n",
    "print(y_teste['score'].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "# aqui vamos analisar\n",
    "# X_treino e y_treino t√™m o mesmo n√∫mero de linhas\n",
    "# y_treino deve ter apenas a coluna score, \n",
    "# a distribui√ß√£o de classes de y_teste deve estar balanceada ou proximas pelo amor de deus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yx1x-6-z-yGY"
   },
   "source": [
    "# 2) Explique com suas palavras, qual o passo a passo para a aplica√ß√£o do algoritmo da √°rvore de decis√£o, n√£o esque√ßa de citar a etapa de avalia√ß√£o do modelo e tamb√©m como podemos melhorar nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goU3eJz64vWl"
   },
   "outputs": [],
   "source": [
    "# eu fiz uma corre√ßao dai ele botou uns termos tecnicos q eu n sabia o nome porem sabia a logica A aplica√ß√£o do algoritmo de √Årvore de Decis√£o envolve algumas etapas principais. Primeiro, realiza-se o tratamento e prepara√ß√£o dos dados, incluindo limpeza, balanceamento e transforma√ß√£o de vari√°veis categ√≥ricas. Em seguida, a base √© dividida em treino e teste, garantindo a avalia√ß√£o da capacidade de generaliza√ß√£o do modelo.\n",
    "\n",
    "# Depois, cria-se o modelo DecisionTreeClassifier, definindo par√¢metros como o crit√©rio de impureza (‚Äúgini‚Äù ou ‚Äúentropy‚Äù) e o random_state, e o modelo √© treinado com os dados de treino. Na sequ√™ncia, ele √© avaliado com m√©tricas como acur√°cia, precis√£o e matriz de confus√£o, comparando os resultados entre treino e teste para verificar poss√≠veis sinais de overfitting.\n",
    "\n",
    "# Por fim, a visualiza√ß√£o da √°rvore permite entender as regras de decis√£o e as vari√°veis mais importantes. Caso o modelo apresente baixa generaliza√ß√£o, podem ser ajustados hiperpar√¢metros como a profundidade m√°xima ou o n√∫mero m√≠nimo de amostras por n√≥, buscando melhorar o desempenho e a interpretabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-wtN8Y24dcg"
   },
   "source": [
    "# 3) Aplique o algortimo da √°rvore de decis√£o aos dados de treinamento, utilizando crit√©rio de Gini e random state = 0.\n",
    "Traga a acur√°cia para o modedlo com os dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTAOXnxS6p1C"
   },
   "outputs": [],
   "source": [
    "modelo = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Avalia√ß√£o no treino\n",
    "y_pred_treino = modelo.predict(X_treino)\n",
    "acuracia_treino = accuracy_score(y_treino, y_pred_treino)\n",
    "print(\"Acur√°cia no treino:\", acuracia_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajytPG6G75jJ"
   },
   "source": [
    "# 4) Aplique o modelo aos dados de teste e realize a avalia√ß√£o dos resultados. N√£o se esque√ßa de avaliar com as suas palavras e comparar o desempenho da base treino com a teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDikimnX8EU2"
   },
   "outputs": [],
   "source": [
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "acuracia_teste = accuracy_score(y_teste, y_pred_teste)\n",
    "print(\"Acur√°cia no teste:\", acuracia_teste)\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o:\\n\", classification_report(y_teste, y_pred_teste))\n",
    "\n",
    "# Matriz de confus√£o\n",
    "cm = confusion_matrix(y_teste, y_pred_teste)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Matriz de Confus√£o - Teste\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Se a acur√°cia no treino for muito maior que no teste ‚Üí o modelo est√° over na verdade o termo correto e overfitting.\n",
    "# Se forem parecidas ‚Üí bom sinal de \"generaliza√ß√£o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIAfA8zl8--k"
   },
   "source": [
    "# 5) Plote a √°rvore de decis√£o.\n",
    "√â poss√≠vel fazer uma avalia√ß√£o visual? Qual a profundidade da √°rvore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NFE88AV9EVT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(modelo, filled=True, feature_names=X_treino.columns, class_names=True, max_depth=3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Profundidade da √°rvore:\", modelo.get_depth())\n",
    "\n",
    "\n",
    "# profundidade mostra a complexidade da √°rvore. Quanto maior, mais o modelo memoriza o treino. \n",
    "# Pela visualiza√ß√£o √© poss√≠vel entender quais vari√°veis t√™m mais influ√™ncia na classifica√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuaEvREG9bz9"
   },
   "source": [
    "# 6) Identifique as 2 principais features do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9W6B2kmV9jYx"
   },
   "outputs": [],
   "source": [
    "importances = pd.Series(modelo.feature_importances_, index=X_treino.columns)\n",
    "principais = importances.sort_values(ascending=False).head(2)\n",
    "print(\"As duas principais features s√£o:\")\n",
    "print(principais)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM27EgfT9zfT"
   },
   "source": [
    "# 7) Rode um modelo de √°rvore de decis√£o apenas com as 2 principais features encontradas. E avalie os resultados. Para voc√™ o desempenho da √°rvore est√° melhor que o modelo anterior? Justifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_1IN8UN9zCS"
   },
   "outputs": [],
   "source": [
    "X_treino_reduzido = X_treino[principais.index]\n",
    "X_teste_reduzido = X_teste[principais.index]\n",
    "\n",
    "modelo_reduzido = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "modelo_reduzido.fit(X_treino_reduzido, y_treino)\n",
    "\n",
    "y_pred_reduzido = modelo_reduzido.predict(X_teste_reduzido)\n",
    "\n",
    "print(\"Acur√°cia com 2 features:\", accuracy_score(y_teste, y_pred_reduzido))\n",
    "print(\"\\nRelat√≥rio:\\n\", classification_report(y_teste, y_pred_reduzido))\n",
    "\n",
    "#Com apenas duas vari√°veis, o modelo ficou mais simples e interpret√°vel. A acur√°cia pode diminuir um pouco, mas o modelo fica mais generaliz√°vel e f√°cil de explicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnHjqAsr_MRe"
   },
   "source": [
    "# 8) Compare os resultados obtidos com a √°rvore de decis√£o com os resultados do Naive Bayes (Exerc√≠cio m√≥dulo 20). Qual parece ter se adequado melhor aos dados e tem melhores resultados de avalia√ß√£o? Justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Compara√ß√£o entre a √Årvore de Decis√£o e o Naive Bayes\n",
    "\n",
    "No projeto anterior, aplicamos o algoritmo Naive Bayes para prever o score de cr√©dito de clientes. O modelo apresentou resultados satisfat√≥rios, com boa capacidade de generaliza√ß√£o e rapidez no treinamento. O Naive Bayes foi adequado por ser um m√©todo probabil√≠stico simples, eficiente e interpret√°vel, especialmente quando as vari√°veis s√£o aproximadamente independentes.\n",
    "\n",
    "J√° no modelo atual, com √Årvore de Decis√£o, o objetivo foi compreender como um algoritmo baseado em regras hier√°rquicas se comporta frente ao mesmo problema. A √Årvore de Decis√£o tem a vantagem de capturar rela√ß√µes n√£o lineares e intera√ß√µes entre vari√°veis, algo que o Naive Bayes n√£o faz. Al√©m disso, permite visualizar graficamente as decis√µes e identificar quais vari√°veis mais influenciam o resultado, tornando a interpreta√ß√£o mais intuitiva.\n",
    "\n",
    "Ao comparar os desempenhos:\n",
    "\n",
    "A acur√°cia da √Årvore de Decis√£o no treino foi superior √† do Naive Bayes, indicando que ela se ajustou muito bem aos dados de treinamento.\n",
    "\n",
    "No entanto, se a acur√°cia no teste for menor, isso pode indicar overfitting, o que √© comum nesse tipo de modelo quando n√£o se controlam par√¢metros como profundidade m√°xima ou n√∫mero m√≠nimo de amostras por n√≥.\n",
    "\n",
    "O Naive Bayes, por outro lado, tende a ser mais est√°vel e generaliz√°vel, mesmo com desempenho ligeiramente inferior.\n",
    "\n",
    "Em resumo:\n",
    "\n",
    "Naive Bayes ‚Üí mais simples, r√°pido e est√°vel, mas com suposi√ß√£o forte de independ√™ncia.\n",
    "\n",
    "√Årvore de Decis√£o ‚Üí mais flex√≠vel e interpret√°vel, mas propensa a overfitting se n√£o for ajustada.\n",
    "\n",
    "Portanto, o modelo que ‚Äúmelhor se adequa‚Äù depende do objetivo:\n",
    "\n",
    "Se a prioridade for interpreta√ß√£o e explica√ß√£o das decis√µes, a √Årvore de Decis√£o √© mais indicada.\n",
    "\n",
    "Se a prioridade for robustez e generaliza√ß√£o, o Naive Bayes pode ser preferido."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
