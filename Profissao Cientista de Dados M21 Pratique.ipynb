{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mEckgFd-NN6"
   },
   "source": [
    "# **MÓDULO 21 - Projeto de Credit Score - Árvore de Decisão**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0glG_vNy-UJb"
   },
   "source": [
    "No módulo 17, vocês realizaram a primeira etapa do projeto de crédito de vocês. Então fizeram o tratamendo dos dados, balancearam as classes, transformaram as variáveis categóricas e separam base de treino e teste. Já no módulo 14, aplicaram a base já tratada o algoritmo de Naive Bayes, onde avaliaram os resultados das previsões. Nesse módulo aplicaremos a nossa base o algoritmo da árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JJKbQFtKyfip"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos encontrados na pasta:\n",
      "CREDIT_SCORE_PROJETO_PARTE1.csv\n",
      "MODULO7.csv\n",
      "X_test.csv\n",
      "X_train_balanced.csv\n",
      "y_test.csv\n",
      "y_train_balanced.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "caminho = r'C:\\Users\\msn_j.000\\Desktop\\henry estudo ebac\\atividades feitas'\n",
    "\n",
    "# Mostrar todos os arquivos CSV na pasta\n",
    "print(\"Arquivos encontrados na pasta:\")\n",
    "for arquivo in os.listdir(caminho):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        print(arquivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piJZ3_sx-uvS"
   },
   "source": [
    "# 1) Comece carregando as bases de treino (X e y) e teste (X e y).\n",
    "Verifique se o número de linhas condiz, se as variáveis estão corretas sendo apenas a de score para y e as demais nas bases de X e por último, se Y está balanceada no teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBjhq9xY-xoQ"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\msn_j.000\\\\Desktop\\\\henry estudo ebac\\\\atividades feitas\\\\X_treino.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m caminho \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmsn_j.000\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhenry estudo ebac\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124matividades feitas\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Carregando as bases\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_treino \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaminho\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mX_treino.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_treino \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaminho\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124my_treino.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m X_teste  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaminho\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mX_teste.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\msn_j.000\\\\Desktop\\\\henry estudo ebac\\\\atividades feitas\\\\X_treino.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho base dos arquivos\n",
    "caminho = r'C:\\Users\\msn_j.000\\Desktop\\henry estudo ebac\\atividades feitas'\n",
    "\n",
    "# Carregando as bases corretas\n",
    "X_treino = pd.read_csv(fr'{caminho}\\X_train_balanced.csv')\n",
    "y_treino = pd.read_csv(fr'{caminho}\\y_train_balanced.csv')\n",
    "X_teste  = pd.read_csv(fr'{caminho}\\X_test.csv')\n",
    "y_teste  = pd.read_csv(fr'{caminho}\\y_test.csv')\n",
    "\n",
    "# Verificando se deu tudo certo\n",
    "print(\"✅ Formas das bases:\")\n",
    "print(\"X_treino:\", X_treino.shape)\n",
    "print(\"y_treino:\", y_treino.shape)\n",
    "print(\"X_teste:\", X_teste.shape)\n",
    "print(\"y_teste:\", y_teste.shape)\n",
    "\n",
    "# Conferindo colunas e distribuição das classes\n",
    "print(\"\\n📋 Colunas de X_treino:\", X_treino.columns.tolist())\n",
    "print(\"\\n📊 Distribuição das classes em y_treino:\")\n",
    "print(y_treino['score'].value_counts(normalize=True))\n",
    "print(\"\\n📊 Distribuição das classes em y_teste:\")\n",
    "print(y_teste['score'].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "# aqui vamos analisar\n",
    "# X_treino e y_treino têm o mesmo número de linhas\n",
    "# y_treino deve ter apenas a coluna score, \n",
    "# a distribuição de classes de y_teste deve estar balanceada ou proximas pelo amor de deus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yx1x-6-z-yGY"
   },
   "source": [
    "# 2) Explique com suas palavras, qual o passo a passo para a aplicação do algoritmo da árvore de decisão, não esqueça de citar a etapa de avaliação do modelo e também como podemos melhorar nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goU3eJz64vWl"
   },
   "outputs": [],
   "source": [
    "# eu fiz uma correçao dai ele botou uns termos tecnicos q eu n sabia o nome porem sabia a logica A aplicação do algoritmo de Árvore de Decisão envolve algumas etapas principais. Primeiro, realiza-se o tratamento e preparação dos dados, incluindo limpeza, balanceamento e transformação de variáveis categóricas. Em seguida, a base é dividida em treino e teste, garantindo a avaliação da capacidade de generalização do modelo.\n",
    "\n",
    "# Depois, cria-se o modelo DecisionTreeClassifier, definindo parâmetros como o critério de impureza (“gini” ou “entropy”) e o random_state, e o modelo é treinado com os dados de treino. Na sequência, ele é avaliado com métricas como acurácia, precisão e matriz de confusão, comparando os resultados entre treino e teste para verificar possíveis sinais de overfitting.\n",
    "\n",
    "# Por fim, a visualização da árvore permite entender as regras de decisão e as variáveis mais importantes. Caso o modelo apresente baixa generalização, podem ser ajustados hiperparâmetros como a profundidade máxima ou o número mínimo de amostras por nó, buscando melhorar o desempenho e a interpretabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-wtN8Y24dcg"
   },
   "source": [
    "# 3) Aplique o algortimo da árvore de decisão aos dados de treinamento, utilizando critério de Gini e random state = 0.\n",
    "Traga a acurácia para o modedlo com os dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTAOXnxS6p1C"
   },
   "outputs": [],
   "source": [
    "modelo = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Avaliação no treino\n",
    "y_pred_treino = modelo.predict(X_treino)\n",
    "acuracia_treino = accuracy_score(y_treino, y_pred_treino)\n",
    "print(\"Acurácia no treino:\", acuracia_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajytPG6G75jJ"
   },
   "source": [
    "# 4) Aplique o modelo aos dados de teste e realize a avaliação dos resultados. Não se esqueça de avaliar com as suas palavras e comparar o desempenho da base treino com a teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDikimnX8EU2"
   },
   "outputs": [],
   "source": [
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "acuracia_teste = accuracy_score(y_teste, y_pred_teste)\n",
    "print(\"Acurácia no teste:\", acuracia_teste)\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_teste, y_pred_teste))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_teste, y_pred_teste)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Matriz de Confusão - Teste\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Se a acurácia no treino for muito maior que no teste → o modelo está over na verdade o termo correto e overfitting.\n",
    "# Se forem parecidas → bom sinal de \"generalização\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIAfA8zl8--k"
   },
   "source": [
    "# 5) Plote a árvore de decisão.\n",
    "É possível fazer uma avaliação visual? Qual a profundidade da árvore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NFE88AV9EVT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(modelo, filled=True, feature_names=X_treino.columns, class_names=True, max_depth=3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Profundidade da árvore:\", modelo.get_depth())\n",
    "\n",
    "\n",
    "# profundidade mostra a complexidade da árvore. Quanto maior, mais o modelo memoriza o treino. \n",
    "# Pela visualização é possível entender quais variáveis têm mais influência na classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuaEvREG9bz9"
   },
   "source": [
    "# 6) Identifique as 2 principais features do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9W6B2kmV9jYx"
   },
   "outputs": [],
   "source": [
    "importances = pd.Series(modelo.feature_importances_, index=X_treino.columns)\n",
    "principais = importances.sort_values(ascending=False).head(2)\n",
    "print(\"As duas principais features são:\")\n",
    "print(principais)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM27EgfT9zfT"
   },
   "source": [
    "# 7) Rode um modelo de árvore de decisão apenas com as 2 principais features encontradas. E avalie os resultados. Para você o desempenho da árvore está melhor que o modelo anterior? Justifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_1IN8UN9zCS"
   },
   "outputs": [],
   "source": [
    "X_treino_reduzido = X_treino[principais.index]\n",
    "X_teste_reduzido = X_teste[principais.index]\n",
    "\n",
    "modelo_reduzido = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "modelo_reduzido.fit(X_treino_reduzido, y_treino)\n",
    "\n",
    "y_pred_reduzido = modelo_reduzido.predict(X_teste_reduzido)\n",
    "\n",
    "print(\"Acurácia com 2 features:\", accuracy_score(y_teste, y_pred_reduzido))\n",
    "print(\"\\nRelatório:\\n\", classification_report(y_teste, y_pred_reduzido))\n",
    "\n",
    "#Com apenas duas variáveis, o modelo ficou mais simples e interpretável. A acurácia pode diminuir um pouco, mas o modelo fica mais generalizável e fácil de explicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnHjqAsr_MRe"
   },
   "source": [
    "# 8) Compare os resultados obtidos com a árvore de decisão com os resultados do Naive Bayes (Exercício módulo 20). Qual parece ter se adequado melhor aos dados e tem melhores resultados de avaliação? Justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Comparação entre a Árvore de Decisão e o Naive Bayes\n",
    "\n",
    "No projeto anterior, aplicamos o algoritmo Naive Bayes para prever o score de crédito de clientes. O modelo apresentou resultados satisfatórios, com boa capacidade de generalização e rapidez no treinamento. O Naive Bayes foi adequado por ser um método probabilístico simples, eficiente e interpretável, especialmente quando as variáveis são aproximadamente independentes.\n",
    "\n",
    "Já no modelo atual, com Árvore de Decisão, o objetivo foi compreender como um algoritmo baseado em regras hierárquicas se comporta frente ao mesmo problema. A Árvore de Decisão tem a vantagem de capturar relações não lineares e interações entre variáveis, algo que o Naive Bayes não faz. Além disso, permite visualizar graficamente as decisões e identificar quais variáveis mais influenciam o resultado, tornando a interpretação mais intuitiva.\n",
    "\n",
    "Ao comparar os desempenhos:\n",
    "\n",
    "A acurácia da Árvore de Decisão no treino foi superior à do Naive Bayes, indicando que ela se ajustou muito bem aos dados de treinamento.\n",
    "\n",
    "No entanto, se a acurácia no teste for menor, isso pode indicar overfitting, o que é comum nesse tipo de modelo quando não se controlam parâmetros como profundidade máxima ou número mínimo de amostras por nó.\n",
    "\n",
    "O Naive Bayes, por outro lado, tende a ser mais estável e generalizável, mesmo com desempenho ligeiramente inferior.\n",
    "\n",
    "Em resumo:\n",
    "\n",
    "Naive Bayes → mais simples, rápido e estável, mas com suposição forte de independência.\n",
    "\n",
    "Árvore de Decisão → mais flexível e interpretável, mas propensa a overfitting se não for ajustada.\n",
    "\n",
    "Portanto, o modelo que “melhor se adequa” depende do objetivo:\n",
    "\n",
    "Se a prioridade for interpretação e explicação das decisões, a Árvore de Decisão é mais indicada.\n",
    "\n",
    "Se a prioridade for robustez e generalização, o Naive Bayes pode ser preferido."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
